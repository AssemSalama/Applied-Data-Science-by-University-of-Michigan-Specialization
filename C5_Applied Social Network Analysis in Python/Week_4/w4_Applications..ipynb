{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Module Four`\n",
    "*you will explore the evolution of networks over time. You will learn about different models that generate networks with realistic features such as the Preferential Attachment Model and Small World Networks. You will also explore the link prediction problem, where you will learn useful features that can predict whether a pair of disconnected nodes will be connected in the future. In the assignment, you will be challenged to identify which model generated a given network. Additionally, you will have the opportunity to combine different concepts of the course by predicting the salary, position, and future connections of the employees of a company using their logs of email exchanges.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Preferential Attachment Model.\n",
    "![1](1.png)\n",
    "![2](2.png)\n",
    "![4](4.png)\n",
    "![3](3.png)\n",
    "![5](5.png)\n",
    "![6](6.png)\n",
    "**What does the degree distribution look like for real networks?**\n",
    "![7](7.png)\n",
    "\n",
    "- There are two things to notice about these degree distributions. The `first` thing is that they're all in log-log scale, meaning that the x-axis and the y-axis are both on log scale rather than linear scale.\n",
    "\n",
    "- The `second` thing to notice is that, for at least part of these distributions, they tend to look like straight lines for all three cases. When you put those two things together when you have a degree distribution on a log-log scale and it looks kind of like a straight line, then we say that this degree distribution looks kind of like a **power law**.\n",
    "![8](8.png)\n",
    "\n",
    "\n",
    "The thing to know about power law degree distributions is that they tend to have most of the nodes with very, very small degree, but you have a few nodes that accumulate a very, very large degree:\n",
    "\n",
    "- For example, if we look at the degree distribution for Network A, we have that most actors have a very small degree so they have appeared in movies with a very small number of other actors, but few actors actually appear in a movie with many, many actors. Some appear in at least one movie with almost 1,000 actors. You can notice that when you look at this degree distribution, these actors have accumulated a degree that's very large, almost 1,000. Whereas, most actors actually have a very small degree. And that's typical of power law degree distributions.\n",
    "\n",
    "\n",
    "One of the things we try to ask when we see something like this is, what could explain this property that we observe happening in many different networks? :\n",
    "- The way we try to answer this question is by coming up with models that generate networks that make a few assumptions about how these networks get formed, and then they give rise to whatever properties we observe. So in this case, the question would be, `can we come up with a model that generates a network that has a power law-like degree distribution?`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![9](9.png)\n",
    "\n",
    "- You can see how this continues. The thing to notice here is that as node two started to get larger and larger degree, its probability of getting a new edge became larger and larger as well. There is this sort of rich get richer phenomenon, where as the nodes get larger and larger degree, they also start to become more and more likely to increase their degree.\n",
    "\n",
    "\n",
    "- What we can prove about this particular mechanism is that it gives rise to a `power law`. It approaches a power law as the number of nodes gets larger, and larger, and larger. \n",
    "\n",
    "![10](10.png)\n",
    "\n",
    "So it matches the kind of degree distribution that we see in these real networks. This type of modeling technique allows us to explain or at least have some hypothesis for what kind of mechanism could give and rise to this shape of the degree distribution that we observe:\n",
    "- For example, if we believe that a very popular actor that has appeared with many other actors in movies has a higher likelihood of getting an additional actor to co-appear in a movie than a maybe less popular actor that has not appeared with many other actors in movies, then this is the kind of mechanism that could be explaining the sort of very skewed power law distribution that we observed.\n",
    "\n",
    "![11](11.png)\n",
    "![12](12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Small World Networks.\n",
    "we're going to talk about the small world phenomenon, which suggests that the world is small in the sense that, we're all connected by very short paths between each other:\n",
    "\n",
    "- But how can we measure these paths, and how short are they really? So in the 1960s, a researcher named Stanley Milgram was wondering about this very question. And he set out to create and experiment that would allow him to measure `how long these paths are, and whether or not they really exist`.\n",
    "![13](13.png)\n",
    "![14](14.png)\n",
    "![15](15.png)\n",
    "![16](16.png)\n",
    "\n",
    "- **So what this tells us is that, if we look at these real networks that have millions and millions of people, the average shortest path between pairs of nodes tend to be on average or median, tends to be `very small`.**\n",
    "\n",
    "**So that's the first property that I wanted to discuss today. The other property that I wanted to talk about is this `clustering coefficient` property, which we've talked about before.**\n",
    "\n",
    "![17](17.png)\n",
    "![18](18.png)\n",
    "\n",
    "**So let's create one of a 1,000 nodes and parameter m of 4, that means that each new node is going to attach to 4 existing nodes. And let's see what its average clustering is. Well in this case, it's 0.02 which is pretty small compared to the networks that we had seen before. Now for the average shortest path length, it is 4.16, which is pretty small, it's pretty decent. So it seems that `it get's one of the properties but not the other`.**\n",
    "![19](19.png)\n",
    "\n",
    "- **It seems like the preferential attachment model, while it has the small average shortest path property, but fails to have high cluster coefficient property. And the reason is that, there is no mechanism in the preferential attachment model that would favor triangle formation. So it's natural that it just doesn't have that property. So now let's talk about a new model called the `small world model` that actually gives network that have these two properties.**\n",
    "![20](20.png)\n",
    "![21](21.png)\n",
    "## Now , we're done , and this is the final shape we got.\n",
    "![22](22.png)\n",
    "![23](23.png)\n",
    "\n",
    "**`p = 0` so we're looking at this type of network. What we have is a completely regular lattice. So there is no rewiring, and because every node is connected to k of its neighbors, then there are lots of triangles that get formed locally, right?:**\n",
    "\n",
    "- Because, well it depends on the value of k, but if k is sort of large enough, then you start to form many triangles. And so this network will have pretty high clustering coefficient because it purposely going to form triangles in the beginning. And then nothing gets rewire, nothing gets changed, so it has a pretty high clustering coefficient. However, if you imagine there's been a very large network, you can imagine that the distances between nodes can get very large, right. So if you're in one side of the ring to get to the other side of the ring, you can hop a little bit but there is no long bridge that can take you there. And so, we expect that the distances would be long.\n",
    "\n",
    "**`p = 1` what's happening here is that, we're going to rewire every single edge. And so this network is now completely random:**\n",
    "\n",
    "- So we've created a bunch of long bridges. And so presumably, distances are pretty small between different nodes. But now, we kind of destroyed the sort of local structure that we had before. And so now we probably don't have many triangles there. And so while the distances are small, now the clustering also got very small.\n",
    "\n",
    "![24](24.png)\n",
    "**So for these types of values of p, we can achieve both of the properties that we wanted. The average shortest path being small, single digit, and the average clustering coefficient being pretty large.**\n",
    "![25](25.png)\n",
    "\n",
    "**So most nodes have degree 6. A few of them have 5 and 7, and I think maybe 1 or various small number of them has degree 4 and 8, and that's about it. And this makes sense because, well, the rewiring probabilities is very small so most of the edges aren't going to be rewired. So most of the nodes are going to stay with their degree of 6 that they had in the beginning when the ring was first formed. And because there's no mechanism that sort of makes some nodes accumulate a very large degree, then none of them do.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Q` : Is the degree distribution of small world network a power law distribution?\n",
    "\n",
    "`A` : The degree distribution of small world network is not a power law because the degree of most nodes lie in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disconnection Problem.\n",
    "There are certain variants of the small world network in NetworkX that you can use. So the first one addresses and issue that small world networks, in general, can become disconnected. So there's nothing that makes them so that they necessarily are in a single component. If you rewire too many of the edges`(p is large)`, you could end up with more than one connected component. And this is sometimes something we don't want. Sometimes we want to create a network that is connected, where every node can reach every other node.\n",
    "### Solution.\n",
    "![26](26.png)\n",
    "![27](27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Link Prediction.\n",
    "\n",
    "Today we're going to look at a related problem which is given a fixed network, can we predict how this network is going to look in the future. And more specifically, we're going to be looking at the link prediction problem. Which is given a network, can we predict which edges are going to be formed in the future? :\n",
    "\n",
    "- This problem has a lot of applications, for example if you're Facebook and you want to create a friend recommendation algorithm or a friend recommender to tell people who they should friend. Then, basically you're solving this problem. You're looking at the current Facebook network and you're trying to predict which new friendships are likely to form in the future.\n",
    "![28](28.png)\n",
    "![29](29.png)\n",
    "![30](30.png)\n",
    "\n",
    "And so if we start to compare between different edges, for example we look at the pair `A, G` and the pair `H, I`, and ask, `which one of these two is more likely to become connected?`:\n",
    "\n",
    "- Then by looking at the number of common neighbors, we actually can't tell, because both of these have exactly 1 neighbor in common, **So we are in need to different measure**.\n",
    "![31](31.png)\n",
    "\n",
    "`Q`: What is the Jaccard Coefficient between node A and F?\n",
    "\n",
    "`A`: J_coeff = |{E}|/|{B, C, D, E, G}|=⅕=0.2\n",
    "![32](32.png)\n",
    "![33](33.png)\n",
    "![34](34.png)\n",
    "\n",
    "`Q`: What is the Resource Allocation index of Node I and H?\n",
    "\n",
    "`A`: Node I and H have only one common neighbor: G. The degree of node G is 4. Hence the Resource Allocation index is ¼ = 0.25.\n",
    "![35](35.png)\n",
    "![36](36.png)\n",
    "![37](37.png)\n",
    "![38](38.png)\n",
    "![39](39.png)\n",
    "![40](40.png)\n",
    "![41](41.png)\n",
    "`Q` :What is the Common Neighbor Soundarajan-Hopcroft score of node I and H?\n",
    "\n",
    "`A` : Node I and H have only one common neighbor G. G is in the same community hence f(u)=1. The result is 1+1=2.\n",
    "![42](42.png)\n",
    "![43](43.png)\n",
    "![44](44.png)\n",
    "![45](45.png)\n",
    "![46](46.png)\n",
    "![47](47.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Notes.\n",
    "**I want to point out two things:**\n",
    "\n",
    "- `One`, none of these measures actually tell you whether or not you should predict that a particular edge is going to come up in the future or not. It just gives a score that is supposed to give you a sense for whether or not these two nodes are likely to connect.\n",
    "\n",
    "\n",
    "- `Second` thing is that different measures can give you different scores, right? So for example, we saw that some measures would give the edge H, I, a higher score that A,G and some measures would do the opposite. And so these measures aren't necessarily consistent with each other.\n",
    "\n",
    "\n",
    "- `SOLUTION`So if you're actually trying to solve the link-prediction problem, typically what would happen is that you would use these measures as features. And then you would use a classifier, if you have some label data, you would train a classifier and use these measures as features in order to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
