{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "\n",
    "\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "\n",
    "\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "\n",
    "\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "\n",
    "\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "\n",
    "\n",
    "* 6/2008; 12/2009\n",
    "\n",
    "\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         03/25/93 Total time of visit (in minutes):\\n\n",
       "1                       6/18/85 Primary Care Doctor:\\n\n",
       "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3                7 on 9/27/75 Audit C Score Current:\\n\n",
       "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "5                    .Per 7/06/79 Movement D/O note:\\n\n",
       "6    4, 5/18/78 Patient's thoughts about current su...\n",
       "7    10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
       "8                         3/7/86 SOS-10 Total Score:\\n\n",
       "9             (4/10/71)Score-1Audit C Score Current:\\n\n",
       "dtype: object"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('data\\dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, we need to know how many medical note we're dealing with.\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Instead of what we did above we can just create a Regex for each single scenario of date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most programming languages, whitespace `\\s` is defined to mean spaces, tabs, carriage returns, newlines, and maybe a few other characters that behave similarly: \n",
    "- `-` don't belong to \\s so you need to write it separately.\n",
    "\n",
    "- Then, non-whitespace `\\S` would be all the other characters. This would include all the alphabetical and numeric characters, punctuation`, belongs`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![variation_list](variation_list.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       500 non-null    object\n",
      " 1   1       125 non-null    object\n",
      " 2   2       34 non-null     object\n",
      " 3   3       69 non-null     object\n",
      " 4   4       0 non-null      object\n",
      " 5   5       115 non-null    object\n",
      " 6   6       112 non-null    object\n",
      " 7   7       45 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/25/93</td>\n",
       "      <td>03/25/93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/18/85</td>\n",
       "      <td>6/18/85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/8/71</td>\n",
       "      <td>7/8/71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/27/75</td>\n",
       "      <td>9/27/75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/6/96</td>\n",
       "      <td>2/6/96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7/06/79</td>\n",
       "      <td>7/06/79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5/18/78</td>\n",
       "      <td>5/18/78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/24/89</td>\n",
       "      <td>10/24/89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/7/86</td>\n",
       "      <td>3/7/86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4/10/71</td>\n",
       "      <td>4/10/71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2    3    4    5    6    7\n",
       "0  03/25/93  03/25/93  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "1   6/18/85   6/18/85  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "2    7/8/71    7/8/71  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "3   9/27/75   9/27/75  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "4    2/6/96    2/6/96  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "5   7/06/79   7/06/79  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "6   5/18/78   5/18/78  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "7  10/24/89  10/24/89  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "8    3/7/86    3/7/86  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "9   4/10/71   4/10/71  NaN  NaN  NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '(\\d{1,2}[\\/|\\-]\\d{1,2}[\\/|\\-|\\ ]\\d{2,4})'\n",
    "s2 = '((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[\\-\\s]\\d{1,2}[,]{0,1}[\\-\\s]\\d{2,4})'\n",
    "s3 = '(\\d{1,2}[\\s](?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[\\-|\\s]\\d{2,4})'\n",
    "s4 = '((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[\\-|\\s]\\d{2,4}[\\S]*[\\s]\\d{2,4})'\n",
    "s5 = '((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[\\-|\\s]\\d{2,4})'\n",
    "s6 = '(\\d{1,2}[\\/|\\-][1|2]\\d{3})'\n",
    "s7 = '([1|2]\\d{3})'\n",
    "\n",
    "full_regex = '(%s|%s|%s|%s|%s|%s|%s)' %(s1, s2, s3, s4, s5, s6,s7)\n",
    "\n",
    "parsed_date = df.str.extract(full_regex)\n",
    "\n",
    "# To make sure that there is no NAN in the first column`0`. \n",
    "print(parsed_date.info())\n",
    "parsed_date.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decemeber 1978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'24 Jan 2001'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there was a problem in the line num 125&313 which is that i didn't write a \n",
    "# regex to match it so i needed to go above and write scenario_4.\n",
    "\n",
    "# check:\n",
    "print(parsed_date.iloc[313,0])\n",
    "parsed_date.iloc[125,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5/2000'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this was a problem that was giving us `67 5/2000` that lead\n",
    "# to remove the `\\space` from the s1. \n",
    "parsed_date.iloc[392,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the time to convert these dates to a timestamp form \n",
    "# using pd.to_datetime():\n",
    "\n",
    "# pd.to_datetime(parsed_date)\n",
    "# i got :AttributeError: 'int' object has no attribute 'lower' \n",
    "# which means that there are spelling mistakes that to_datetime()\n",
    "# doesn't understand.\n",
    "\n",
    "# cut the df to make a series from 1st column.\n",
    "parsed_date = parsed_date.iloc[:,0]\n",
    "\n",
    "# correct the spelling mistakes.\n",
    "parsed_date = parsed_date.str.replace('Janaury', 'January')\n",
    "parsed_date = parsed_date.str.replace('Decemeber', 'December')\n",
    "\n",
    "# finally, convert to datetime form.\n",
    "# That will apply all the rules were given above.\n",
    "parsed_date_converted = pd.to_datetime(parsed_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9     1971-04-10\n",
      "84    1971-05-18\n",
      "2     1971-07-08\n",
      "53    1971-07-11\n",
      "28    1971-09-12\n",
      "         ...    \n",
      "231   2016-05-01\n",
      "141   2016-05-30\n",
      "186   2016-10-13\n",
      "161   2016-10-19\n",
      "413   2016-11-01\n",
      "Name: 0, Length: 500, dtype: datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([  9,  84,   2,  53,  28, 474, 153,  13, 129,  98,\n",
       "            ...\n",
       "            152, 235, 464, 253, 427, 231, 141, 186, 161, 413],\n",
       "           dtype='int64', length=500)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the sorting phase:\n",
    "sorting = parsed_date_converted.sort_values(ascending= True)\n",
    "print(sorting)\n",
    "\n",
    "# get the index as result of the function.\n",
    "sorting.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2        2\n",
       "3       53\n",
       "4       28\n",
       "      ... \n",
       "495    231\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "Length: 500, dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_sorter():\n",
    "    s1 = '(\\d{1,2}[\\/|\\-]\\d{1,2}[\\/|\\-|\\ ]\\d{2,4})'\n",
    "    s2 = '((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[\\-\\s]\\d{1,2}[,]{0,1}[\\-\\s]\\d{2,4})'\n",
    "    s3 = '(\\d{1,2}[\\s](?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[\\-|\\s]\\d{2,4})'\n",
    "    s4 = '((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[\\-|\\s]\\d{2,4}[\\S]*[\\s]\\d{2,4})'\n",
    "    s5 = '((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[\\S]*[\\-|\\s]\\d{2,4})'\n",
    "    s6 = '(\\d{1,2}[\\/|\\-][1|2]\\d{3})'\n",
    "    s7 = '([1|2]\\d{3})'\n",
    "\n",
    "    full_regex = '(%s|%s|%s|%s|%s|%s|%s)' %(s1, s2, s3, s4, s5, s6,s7)\n",
    "    parsed_date = df.str.extract(full_regex)\n",
    "    \n",
    "    # cut the df to make a series from 1st column.\n",
    "    parsed_date = parsed_date.iloc[:,0]\n",
    "\n",
    "    # correct the spelling mistakes.\n",
    "    parsed_date = parsed_date.str.replace('Janaury', 'January')\n",
    "    parsed_date = parsed_date.str.replace('Decemeber', 'December')\n",
    "\n",
    "    # finally, convert to datetime form.\n",
    "    # That will apply all the rules were given above.\n",
    "    parsed_date_converted = pd.to_datetime(parsed_date)\n",
    "    \n",
    "    # Now the sorting phase:\n",
    "    sorting = parsed_date_converted.sort_values(ascending= True)\n",
    "    # get the index as result of the function.\n",
    "    # put the indexes into Pd Series.\n",
    "    sorting_indexes = pd.Series(sorting.index)\n",
    "        \n",
    "    return sorting_indexes\n",
    "\n",
    "date_sorter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
